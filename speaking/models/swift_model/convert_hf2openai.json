{"^encoder\\.layers\\.(\\d+)\\.self_attn.k_proj\\.(\\w+)$": "encoder.blocks.\\1.attn.key.\\2", "^encoder\\.layers\\.(\\d+)\\.self_attn.out_proj\\.(\\w+)$": "encoder.blocks.\\1.attn.out.\\2", "^encoder\\.layers\\.(\\d+)\\.self_attn.q_proj\\.(\\w+)$": "encoder.blocks.\\1.attn.query.\\2", "^encoder\\.layers\\.(\\d+)\\.self_attn.v_proj\\.(\\w+)$": "encoder.blocks.\\1.attn.value.\\2", "^encoder\\.layers\\.(\\d+)\\.self_attn_layer_norm\\.(\\w+)$": "encoder.blocks.\\1.attn_ln.\\2", "^encoder\\.layers\\.(\\d+)\\.fc1\\.(\\w+)$": "encoder.blocks.\\1.mlp.0.\\2", "^encoder\\.layers\\.(\\d+)\\.fc2\\.(\\w+)$": "encoder.blocks.\\1.mlp.2.\\2", "^encoder\\.layers\\.(\\d+)\\.final_layer_norm\\.(\\w+)$": "encoder.blocks.\\1.mlp_ln.\\2", "^encoder\\.embed_positions\\.weight$": "encoder.positional_embedding", "^encoder\\.layer_norm\\.(\\w+)$": "encoder.ln_post.\\1", "^encoder\\.(\\w+)\\.(\\w+)": "encoder.\\1.\\2", "^decoder\\.embed_positions\\.weight$": "decoder.positional_embedding", "^decoder\\.embed_tokens\\.weight$": "decoder.token_embedding.weight", "^decoder\\.layer_norm\\.(\\w+)$": "decoder.ln.\\1", "^decoder\\.layers\\.(\\d+)\\.encoder_attn\\.k_proj.(\\w+)$": "decoder.blocks.\\1.cross_attn.key.\\2", "^decoder\\.layers\\.(\\d+)\\.encoder_attn\\.out_proj.(\\w+)$": "decoder.blocks.\\1.cross_attn.out.\\2", "^decoder\\.layers\\.(\\d+)\\.encoder_attn\\.q_proj.(\\w+)$": "decoder.blocks.\\1.cross_attn.query.\\2", "^decoder\\.layers\\.(\\d+)\\.encoder_attn\\.v_proj.(\\w+)$": "decoder.blocks.\\1.cross_attn.value.\\2", "^decoder\\.layers\\.(\\d+)\\.encoder_attn_layer_norm\\.(\\w+)$": "decoder.blocks.\\1.cross_attn_ln.\\2", "^decoder\\.layers\\.(\\d+)\\.self_attn\\.k_proj\\.(\\w+)$": "decoder.blocks.\\1.attn.key.\\2", "^decoder\\.layers\\.(\\d+)\\.self_attn\\.out_proj\\.(\\w+)$": "decoder.blocks.\\1.attn.out.\\2", "^decoder\\.layers\\.(\\d+)\\.self_attn\\.q_proj\\.(\\w+)$": "decoder.blocks.\\1.attn.query.\\2", "^decoder\\.layers\\.(\\d+)\\.self_attn\\.v_proj\\.(\\w+)$": "decoder.blocks.\\1.attn.value.\\2", "^decoder\\.layers\\.(\\d+)\\.self_attn_layer_norm\\.(\\w+)$": "decoder.blocks.\\1.attn_ln.\\2", "^decoder\\.layers\\.(\\d+)\\.fc1\\.(\\w+)$": "decoder.blocks.\\1.mlp.0.\\2", "^decoder\\.layers\\.(\\d+)\\.fc2\\.(\\w+)$": "decoder.blocks.\\1.mlp.2.\\2", "^decoder\\.layers\\.(\\d+)\\.final_layer_norm\\.(\\w+)$": "decoder.blocks.\\1.mlp_ln.\\2"}